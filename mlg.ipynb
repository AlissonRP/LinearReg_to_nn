{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From MLG to nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(41)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = torch.from_numpy(np.random.exponential(scale = 15,size = (15,4)))\n",
    "betas = torch.tensor([[1.,3.,15.,-2.]], dtype=torch.float64)\n",
    "b0 = torch.tensor([[2.]], dtype=torch.float64)\n",
    "y = X @ betas.t() + b0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 261.2693],\n",
       "        [  60.0724],\n",
       "        [ 144.7189],\n",
       "        [ 167.7342],\n",
       "        [ 329.7891],\n",
       "        [ 182.9445],\n",
       "        [ 110.9456],\n",
       "        [  79.9302],\n",
       "        [1742.1217],\n",
       "        [ 450.8701],\n",
       "        [ 145.6723],\n",
       "        [ 352.7420],\n",
       "        [ 117.3411],\n",
       "        [ 133.8173],\n",
       "        [ 663.0963]], dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11399/301197645.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  y.grad()\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/alissom/Documentos/Projetos_py/mlg/mlg.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/alissom/Documentos/Projetos_py/mlg/mlg.ipynb#ch0000019?line=0'>1</a>\u001b[0m y\u001b[39m.\u001b[39;49mgrad()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nothing new until now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size = 25, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.analyticsvidhya.com/blog/2021/08/linear-regression-and-gradient-descent-in-pytorch/\n",
    "def rmse(y,y_hat):\n",
    "    return torch.sqrt(((torch.pow(y-y_hat,2))/torch.numel(y)).sum())\n",
    "\n",
    "#loss =  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.7254], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.randn(1,int(X[1].numel()), requires_grad=True, dtype=torch.float64)\n",
    "\n",
    "b =  torch.randn(1, requires_grad=True, dtype=torch.float64)\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearReg(inputs):\n",
    "    y_t = inputs @ w.transpose(0,1)  + b\n",
    "    return y_t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(505.0479, dtype=torch.float64, grad_fn=<SqrtBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LinearReg(X)\n",
    "loss = rmse(y,LinearReg(X))\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "w.grad.zero_()\n",
    "b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6461, dtype=torch.float64, grad_fn=<SqrtBackward>)\n",
      "tensor(0.6461, dtype=torch.float64, grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "for i in range(1000):    \n",
    "    y_hat = LinearReg(X)\n",
    "    loss = rmse(y,y_hat)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "        b -= learning_rate * b.grad\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "    if i == 50 or i==900:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0184,  3.0285, 15.0179, -1.9772]], dtype=torch.float64,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 261.2693],\n",
       "        [  60.0724],\n",
       "        [ 144.7189],\n",
       "        [ 167.7342],\n",
       "        [ 329.7891],\n",
       "        [ 182.9445],\n",
       "        [ 110.9456],\n",
       "        [  79.9302],\n",
       "        [1742.1217],\n",
       "        [ 450.8701],\n",
       "        [ 145.6723],\n",
       "        [ 352.7420],\n",
       "        [ 117.3411],\n",
       "        [ 133.8173],\n",
       "        [ 663.0963]], dtype=torch.float64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(df.data,df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2859.6903987680657"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(reg.predict(df.data),df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearReg():\n",
    "   def __init__(self):\n",
    "      self.w = torch.randn(1,int(X[1].numel()), requires_grad=True)\n",
    "      self.b = torch.randn(int(X.numel()/X[1].numel()), 1, requires_grad=True)\n",
    "   def LinearReg(X):\n",
    "      y = X.float() @ self.w.transpose(0,1) + self.b\n",
    "      return self.y\n",
    "\n",
    "   def rmse(self,y,y_hat):\n",
    "      return torch.sqrt(((torch.pow(self.y-self.y_hat,2))/torch.numel(self.y)).sum())\n",
    "\n",
    "   def fit(self,X):\n",
    "      learning_rate = 0.01\n",
    "      for i in range(300):\n",
    "         y_hat = LinearReg(X)\n",
    "         loss = rmse(self.y,y_hat)\n",
    "         loss.backward()\n",
    "         with torch.no_grad():\n",
    "            w -= learning_rate * self.w.grad\n",
    "            b -= learning_rate * self.b.grad\n",
    "            self.w.grad = None\n",
    "            self.b.grad = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[151.],\n",
       "        [ 75.],\n",
       "        [141.],\n",
       "        [206.],\n",
       "        [135.],\n",
       "        [ 97.],\n",
       "        [138.],\n",
       "        [ 63.],\n",
       "        [110.],\n",
       "        [310.],\n",
       "        [101.],\n",
       "        [ 69.],\n",
       "        [179.],\n",
       "        [185.],\n",
       "        [118.],\n",
       "        [171.],\n",
       "        [166.],\n",
       "        [144.],\n",
       "        [ 97.],\n",
       "        [168.],\n",
       "        [ 68.],\n",
       "        [ 49.],\n",
       "        [ 68.],\n",
       "        [245.],\n",
       "        [184.],\n",
       "        [202.],\n",
       "        [137.],\n",
       "        [ 85.],\n",
       "        [131.],\n",
       "        [283.],\n",
       "        [129.],\n",
       "        [ 59.],\n",
       "        [341.],\n",
       "        [ 87.],\n",
       "        [ 65.],\n",
       "        [102.],\n",
       "        [265.],\n",
       "        [276.],\n",
       "        [252.],\n",
       "        [ 90.],\n",
       "        [100.],\n",
       "        [ 55.],\n",
       "        [ 61.],\n",
       "        [ 92.],\n",
       "        [259.],\n",
       "        [ 53.],\n",
       "        [190.],\n",
       "        [142.],\n",
       "        [ 75.],\n",
       "        [142.],\n",
       "        [155.],\n",
       "        [225.],\n",
       "        [ 59.],\n",
       "        [104.],\n",
       "        [182.],\n",
       "        [128.],\n",
       "        [ 52.],\n",
       "        [ 37.],\n",
       "        [170.],\n",
       "        [170.],\n",
       "        [ 61.],\n",
       "        [144.],\n",
       "        [ 52.],\n",
       "        [128.],\n",
       "        [ 71.],\n",
       "        [163.],\n",
       "        [150.],\n",
       "        [ 97.],\n",
       "        [160.],\n",
       "        [178.],\n",
       "        [ 48.],\n",
       "        [270.],\n",
       "        [202.],\n",
       "        [111.],\n",
       "        [ 85.],\n",
       "        [ 42.],\n",
       "        [170.],\n",
       "        [200.],\n",
       "        [252.],\n",
       "        [113.],\n",
       "        [143.],\n",
       "        [ 51.],\n",
       "        [ 52.],\n",
       "        [210.],\n",
       "        [ 65.],\n",
       "        [141.],\n",
       "        [ 55.],\n",
       "        [134.],\n",
       "        [ 42.],\n",
       "        [111.],\n",
       "        [ 98.],\n",
       "        [164.],\n",
       "        [ 48.],\n",
       "        [ 96.],\n",
       "        [ 90.],\n",
       "        [162.],\n",
       "        [150.],\n",
       "        [279.],\n",
       "        [ 92.],\n",
       "        [ 83.],\n",
       "        [128.],\n",
       "        [102.],\n",
       "        [302.],\n",
       "        [198.],\n",
       "        [ 95.],\n",
       "        [ 53.],\n",
       "        [134.],\n",
       "        [144.],\n",
       "        [232.],\n",
       "        [ 81.],\n",
       "        [104.],\n",
       "        [ 59.],\n",
       "        [246.],\n",
       "        [297.],\n",
       "        [258.],\n",
       "        [229.],\n",
       "        [275.],\n",
       "        [281.],\n",
       "        [179.],\n",
       "        [200.],\n",
       "        [200.],\n",
       "        [173.],\n",
       "        [180.],\n",
       "        [ 84.],\n",
       "        [121.],\n",
       "        [161.],\n",
       "        [ 99.],\n",
       "        [109.],\n",
       "        [115.],\n",
       "        [268.],\n",
       "        [274.],\n",
       "        [158.],\n",
       "        [107.],\n",
       "        [ 83.],\n",
       "        [103.],\n",
       "        [272.],\n",
       "        [ 85.],\n",
       "        [280.],\n",
       "        [336.],\n",
       "        [281.],\n",
       "        [118.],\n",
       "        [317.],\n",
       "        [235.],\n",
       "        [ 60.],\n",
       "        [174.],\n",
       "        [259.],\n",
       "        [178.],\n",
       "        [128.],\n",
       "        [ 96.],\n",
       "        [126.],\n",
       "        [288.],\n",
       "        [ 88.],\n",
       "        [292.],\n",
       "        [ 71.],\n",
       "        [197.],\n",
       "        [186.],\n",
       "        [ 25.],\n",
       "        [ 84.],\n",
       "        [ 96.],\n",
       "        [195.],\n",
       "        [ 53.],\n",
       "        [217.],\n",
       "        [172.],\n",
       "        [131.],\n",
       "        [214.],\n",
       "        [ 59.],\n",
       "        [ 70.],\n",
       "        [220.],\n",
       "        [268.],\n",
       "        [152.],\n",
       "        [ 47.],\n",
       "        [ 74.],\n",
       "        [295.],\n",
       "        [101.],\n",
       "        [151.],\n",
       "        [127.],\n",
       "        [237.],\n",
       "        [225.],\n",
       "        [ 81.],\n",
       "        [151.],\n",
       "        [107.],\n",
       "        [ 64.],\n",
       "        [138.],\n",
       "        [185.],\n",
       "        [265.],\n",
       "        [101.],\n",
       "        [137.],\n",
       "        [143.],\n",
       "        [141.],\n",
       "        [ 79.],\n",
       "        [292.],\n",
       "        [178.],\n",
       "        [ 91.],\n",
       "        [116.],\n",
       "        [ 86.],\n",
       "        [122.],\n",
       "        [ 72.],\n",
       "        [129.],\n",
       "        [142.],\n",
       "        [ 90.],\n",
       "        [158.],\n",
       "        [ 39.],\n",
       "        [196.],\n",
       "        [222.],\n",
       "        [277.],\n",
       "        [ 99.],\n",
       "        [196.],\n",
       "        [202.],\n",
       "        [155.],\n",
       "        [ 77.],\n",
       "        [191.],\n",
       "        [ 70.],\n",
       "        [ 73.],\n",
       "        [ 49.],\n",
       "        [ 65.],\n",
       "        [263.],\n",
       "        [248.],\n",
       "        [296.],\n",
       "        [214.],\n",
       "        [185.],\n",
       "        [ 78.],\n",
       "        [ 93.],\n",
       "        [252.],\n",
       "        [150.],\n",
       "        [ 77.],\n",
       "        [208.],\n",
       "        [ 77.],\n",
       "        [108.],\n",
       "        [160.],\n",
       "        [ 53.],\n",
       "        [220.],\n",
       "        [154.],\n",
       "        [259.],\n",
       "        [ 90.],\n",
       "        [246.],\n",
       "        [124.],\n",
       "        [ 67.],\n",
       "        [ 72.],\n",
       "        [257.],\n",
       "        [262.],\n",
       "        [275.],\n",
       "        [177.],\n",
       "        [ 71.],\n",
       "        [ 47.],\n",
       "        [187.],\n",
       "        [125.],\n",
       "        [ 78.],\n",
       "        [ 51.],\n",
       "        [258.],\n",
       "        [215.],\n",
       "        [303.],\n",
       "        [243.],\n",
       "        [ 91.],\n",
       "        [150.],\n",
       "        [310.],\n",
       "        [153.],\n",
       "        [346.],\n",
       "        [ 63.],\n",
       "        [ 89.],\n",
       "        [ 50.],\n",
       "        [ 39.],\n",
       "        [103.],\n",
       "        [308.],\n",
       "        [116.],\n",
       "        [145.],\n",
       "        [ 74.],\n",
       "        [ 45.],\n",
       "        [115.],\n",
       "        [264.],\n",
       "        [ 87.],\n",
       "        [202.],\n",
       "        [127.],\n",
       "        [182.],\n",
       "        [241.],\n",
       "        [ 66.],\n",
       "        [ 94.],\n",
       "        [283.],\n",
       "        [ 64.],\n",
       "        [102.],\n",
       "        [200.],\n",
       "        [265.],\n",
       "        [ 94.],\n",
       "        [230.],\n",
       "        [181.],\n",
       "        [156.],\n",
       "        [233.],\n",
       "        [ 60.],\n",
       "        [219.],\n",
       "        [ 80.],\n",
       "        [ 68.],\n",
       "        [332.],\n",
       "        [248.],\n",
       "        [ 84.],\n",
       "        [200.],\n",
       "        [ 55.],\n",
       "        [ 85.],\n",
       "        [ 89.],\n",
       "        [ 31.],\n",
       "        [129.],\n",
       "        [ 83.],\n",
       "        [275.],\n",
       "        [ 65.],\n",
       "        [198.],\n",
       "        [236.],\n",
       "        [253.],\n",
       "        [124.],\n",
       "        [ 44.],\n",
       "        [172.],\n",
       "        [114.],\n",
       "        [142.],\n",
       "        [109.],\n",
       "        [180.],\n",
       "        [144.],\n",
       "        [163.],\n",
       "        [147.],\n",
       "        [ 97.],\n",
       "        [220.],\n",
       "        [190.],\n",
       "        [109.],\n",
       "        [191.],\n",
       "        [122.],\n",
       "        [230.],\n",
       "        [242.],\n",
       "        [248.],\n",
       "        [249.],\n",
       "        [192.],\n",
       "        [131.],\n",
       "        [237.],\n",
       "        [ 78.],\n",
       "        [135.],\n",
       "        [244.],\n",
       "        [199.],\n",
       "        [270.],\n",
       "        [164.],\n",
       "        [ 72.],\n",
       "        [ 96.],\n",
       "        [306.],\n",
       "        [ 91.],\n",
       "        [214.],\n",
       "        [ 95.],\n",
       "        [216.],\n",
       "        [263.],\n",
       "        [178.],\n",
       "        [113.],\n",
       "        [200.],\n",
       "        [139.],\n",
       "        [139.],\n",
       "        [ 88.],\n",
       "        [148.],\n",
       "        [ 88.],\n",
       "        [243.],\n",
       "        [ 71.],\n",
       "        [ 77.],\n",
       "        [109.],\n",
       "        [272.],\n",
       "        [ 60.],\n",
       "        [ 54.],\n",
       "        [221.],\n",
       "        [ 90.],\n",
       "        [311.],\n",
       "        [281.],\n",
       "        [182.],\n",
       "        [321.],\n",
       "        [ 58.],\n",
       "        [262.],\n",
       "        [206.],\n",
       "        [233.],\n",
       "        [242.],\n",
       "        [123.],\n",
       "        [167.],\n",
       "        [ 63.],\n",
       "        [197.],\n",
       "        [ 71.],\n",
       "        [168.],\n",
       "        [140.],\n",
       "        [217.],\n",
       "        [121.],\n",
       "        [235.],\n",
       "        [245.],\n",
       "        [ 40.],\n",
       "        [ 52.],\n",
       "        [104.],\n",
       "        [132.],\n",
       "        [ 88.],\n",
       "        [ 69.],\n",
       "        [219.],\n",
       "        [ 72.],\n",
       "        [201.],\n",
       "        [110.],\n",
       "        [ 51.],\n",
       "        [277.],\n",
       "        [ 63.],\n",
       "        [118.],\n",
       "        [ 69.],\n",
       "        [273.],\n",
       "        [258.],\n",
       "        [ 43.],\n",
       "        [198.],\n",
       "        [242.],\n",
       "        [232.],\n",
       "        [175.],\n",
       "        [ 93.],\n",
       "        [168.],\n",
       "        [275.],\n",
       "        [293.],\n",
       "        [281.],\n",
       "        [ 72.],\n",
       "        [140.],\n",
       "        [189.],\n",
       "        [181.],\n",
       "        [209.],\n",
       "        [136.],\n",
       "        [261.],\n",
       "        [113.],\n",
       "        [131.],\n",
       "        [174.],\n",
       "        [257.],\n",
       "        [ 55.],\n",
       "        [ 84.],\n",
       "        [ 42.],\n",
       "        [146.],\n",
       "        [212.],\n",
       "        [233.],\n",
       "        [ 91.],\n",
       "        [111.],\n",
       "        [152.],\n",
       "        [120.],\n",
       "        [ 67.],\n",
       "        [310.],\n",
       "        [ 94.],\n",
       "        [183.],\n",
       "        [ 66.],\n",
       "        [173.],\n",
       "        [ 72.],\n",
       "        [ 49.],\n",
       "        [ 64.],\n",
       "        [ 48.],\n",
       "        [178.],\n",
       "        [104.],\n",
       "        [132.],\n",
       "        [220.],\n",
       "        [ 57.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unsqueeze(1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43bae068c0cf3e26bb718341bc98e1eff693d43b80578fe208d1a851c04b5de8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
