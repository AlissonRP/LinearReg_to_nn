{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From MLG to nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(df.data)\n",
    "y = torch.from_numpy(df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0381,  0.0507,  0.0617,  ..., -0.0026,  0.0199, -0.0176],\n",
       "        [-0.0019, -0.0446, -0.0515,  ..., -0.0395, -0.0683, -0.0922],\n",
       "        [ 0.0853,  0.0507,  0.0445,  ..., -0.0026,  0.0029, -0.0259],\n",
       "        ...,\n",
       "        [ 0.0417,  0.0507, -0.0159,  ..., -0.0111, -0.0469,  0.0155],\n",
       "        [-0.0455, -0.0446,  0.0391,  ...,  0.0266,  0.0445, -0.0259],\n",
       "        [-0.0455, -0.0446, -0.0730,  ..., -0.0395, -0.0042,  0.0031]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nothing new until now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size = 25, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.analyticsvidhya.com/blog/2021/08/linear-regression-and-gradient-descent-in-pytorch/\n",
    "def rmse(y,y_hat):\n",
    "    return torch.sqrt(((torch.pow(y-y_hat,2))/torch.numel(y)).sum())\n",
    "\n",
    "loss =  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.3235e+00,  1.4424e+00,  1.0887e+00,  4.8829e-01, -8.6623e-01,\n",
       "         1.2200e-01, -2.1710e-01,  8.7545e-01,  1.5057e+00,  4.6262e-01,\n",
       "        -2.1117e-01,  8.7289e-01,  3.3605e-01, -2.6177e-01,  1.1483e+00,\n",
       "         5.2294e-02, -2.5033e-01, -6.0430e-01, -1.2211e+00,  1.9518e-01,\n",
       "        -4.6250e-01,  9.0810e-02,  2.1900e-01,  1.3171e+00, -6.5161e-01,\n",
       "         1.6252e+00,  3.0523e-02,  5.8338e-01,  5.5603e-01, -2.2033e+00,\n",
       "        -3.4900e-01, -6.6269e-02, -5.2196e-01,  1.4333e+00,  2.0604e-01,\n",
       "         2.0538e-01, -6.2226e-01, -9.7405e-01, -3.5244e-01,  5.6247e-01,\n",
       "         2.1188e-01, -5.7858e-01,  3.0509e+00, -6.5419e-01, -1.0861e+00,\n",
       "         1.1145e+00, -4.7073e-01, -6.5196e-01,  1.1748e+00,  3.8939e-01,\n",
       "         8.3013e-02,  5.9911e-01,  4.6505e-01,  1.2892e-01,  3.5219e-01,\n",
       "        -1.8115e+00,  6.2478e-01, -1.0230e+00, -1.1161e+00,  1.2991e+00,\n",
       "         1.1134e-02,  5.6615e-01, -1.2895e+00,  7.2954e-01,  1.3603e+00,\n",
       "        -4.0245e-01, -1.9348e+00,  1.5938e+00,  1.0590e+00, -1.2695e+00,\n",
       "        -6.8643e-01, -4.4676e-01,  1.3119e+00,  2.9065e-01, -4.8151e-01,\n",
       "        -6.6033e-01, -2.6883e-01,  2.9353e-02,  1.1238e+00, -1.4339e-01,\n",
       "        -1.3405e+00,  8.9384e-01,  9.9489e-01, -9.0515e-01,  1.0467e+00,\n",
       "         1.0703e-01, -7.2196e-01,  4.6125e-01, -2.8928e-01, -2.9851e-01,\n",
       "         3.6924e-01, -1.0023e+00,  3.6360e-01, -1.5947e-01, -9.8167e-01,\n",
       "         5.4709e-01,  2.0290e-01, -1.1144e+00,  8.4554e-01,  7.8151e-01,\n",
       "         3.1536e-01,  5.1518e-02,  1.4394e+00, -1.9173e-01, -1.1764e+00,\n",
       "         1.0557e+00, -7.7156e-01, -1.0898e+00,  3.7848e-01,  8.9870e-01,\n",
       "        -4.2152e-01, -1.2787e+00,  1.6697e+00, -7.3236e-01,  7.4002e-01,\n",
       "        -3.4758e-01, -1.4620e-01,  5.5766e-02,  1.9962e-01,  1.0204e+00,\n",
       "        -3.5580e-01,  5.0422e-01,  8.0816e-02, -1.5396e+00, -8.5961e-01,\n",
       "        -1.1027e+00,  1.3006e-01, -4.1567e-01,  1.2858e+00,  3.5542e-03,\n",
       "        -3.6456e-02,  2.0413e-02,  2.5092e+00, -2.8998e-01,  1.3156e+00,\n",
       "         5.4509e-01,  6.0652e-01,  1.1300e-01,  1.8029e+00,  1.1596e+00,\n",
       "        -4.5724e-01, -4.9369e-01,  5.5632e-01, -8.8385e-01,  2.2587e-01,\n",
       "        -3.9352e-01,  6.8630e-01,  5.8392e-01,  1.1323e+00,  1.2060e+00,\n",
       "        -5.8222e-01,  1.8716e+00, -1.1825e+00, -1.0986e-03, -1.5727e+00,\n",
       "         1.9060e-01,  1.3796e+00, -7.5063e-01,  2.9612e-01,  5.3497e-01,\n",
       "        -1.6787e+00,  6.0817e-01, -1.9362e-01,  1.6880e+00,  2.0924e-01,\n",
       "        -3.2667e-02, -1.0830e+00,  3.3630e-01, -2.3861e-01, -1.5571e+00,\n",
       "         9.6521e-01,  1.1002e+00, -1.3673e+00, -1.0091e-01, -5.2775e-01,\n",
       "        -5.1000e-01, -4.7672e-01,  5.2554e-01,  1.7853e-01,  2.9461e-02,\n",
       "         1.9343e+00, -8.8376e-01, -2.8049e-01, -7.1206e-01, -1.6615e+00,\n",
       "         4.4829e-01, -4.9519e-01,  7.2584e-01, -1.0798e+00,  4.0094e-01,\n",
       "        -1.9242e-01, -1.5138e+00, -7.0467e-01,  2.5304e-01, -7.5275e-01,\n",
       "        -1.4084e+00,  8.5129e-01,  6.2321e-01, -4.1446e-01,  1.7618e-01,\n",
       "        -1.7811e-01, -2.2468e-01, -1.5413e-01, -6.0688e-01, -1.3134e+00,\n",
       "         1.4216e+00,  7.3275e-01,  1.8513e-01, -2.7716e-01, -4.0000e-01,\n",
       "        -1.4993e+00,  6.8957e-01,  1.0574e+00, -5.9864e-01, -1.3261e+00,\n",
       "         1.5903e+00, -4.4591e-01,  1.9980e+00,  1.3974e+00, -4.1171e-01,\n",
       "        -3.1934e+00, -1.3010e+00, -5.1246e-01, -7.4230e-01, -4.3496e-01,\n",
       "         7.8294e-01,  9.3531e-02, -2.1566e-01, -3.1098e-01,  1.7132e+00,\n",
       "         1.4131e+00, -1.8130e-01, -1.3182e+00,  2.2181e-01, -8.3324e-01,\n",
       "        -9.3620e-01, -1.2869e+00, -1.4922e+00,  7.5616e-01,  8.2161e-01,\n",
       "        -1.5061e+00, -3.7207e-01, -8.7017e-02, -6.9224e-02, -1.2208e-01,\n",
       "         8.1147e-01, -1.2867e-01, -3.8665e-01, -1.4222e+00, -1.6865e+00,\n",
       "        -5.9148e-01,  2.9380e-02, -1.3204e+00, -1.2095e+00, -2.8790e-01,\n",
       "        -4.9202e-02,  8.2560e-01, -7.0381e-01,  1.3037e+00, -1.1678e-02,\n",
       "        -6.4776e-01,  8.5769e-01, -2.2174e-01, -9.0121e-01, -2.3431e+00,\n",
       "         3.8115e-01, -6.3250e-01, -7.9387e-01,  1.6253e+00,  8.3645e-01,\n",
       "         1.3437e+00, -4.4528e-01, -4.5804e-01,  5.8416e-01,  1.5673e+00,\n",
       "        -7.8389e-01,  1.1456e+00, -2.7276e-01, -5.9291e-01, -7.2339e-01,\n",
       "         3.0204e-02,  6.3887e-01,  9.1053e-02,  3.5936e-02, -2.7537e-01,\n",
       "         1.5251e-01, -1.0043e+00,  6.6738e-01, -1.2003e+00,  5.2738e-01,\n",
       "        -1.6389e+00, -2.0443e-01, -1.2631e+00,  4.9629e-01, -9.8939e-01,\n",
       "         6.0028e-01,  9.1580e-01,  1.8445e-01,  6.4000e-01,  2.2197e+00,\n",
       "         9.8092e-02, -3.1889e-02, -4.3341e-01, -2.0043e-01, -9.1726e-01,\n",
       "         5.4063e-01, -6.2019e-01,  8.5361e-01, -3.1444e-01, -9.1744e-02,\n",
       "         1.6420e+00,  9.1908e-02,  1.7999e-01, -4.0700e-01, -5.6720e-01,\n",
       "         2.2163e+00, -5.2838e-01,  4.1593e-01, -6.5054e-01, -2.6430e-01,\n",
       "        -4.5229e-01, -3.5681e-01, -1.9869e+00,  8.8772e-01,  1.8026e+00,\n",
       "         4.2002e-01, -2.7407e-01,  6.5536e-01,  1.8957e-01,  9.3390e-01,\n",
       "         5.5045e-01,  1.7484e-01, -3.0932e-02, -2.8509e-01,  3.8949e-02,\n",
       "        -1.4129e+00,  5.6089e-01,  5.2023e-01, -1.4074e+00,  9.5777e-01,\n",
       "        -7.0086e-01, -5.5484e-01,  1.2367e-01,  1.1976e+00,  1.0688e-01,\n",
       "        -3.5344e-01,  1.0856e-01, -1.2963e+00, -9.7606e-01,  1.6626e-01,\n",
       "         1.3346e+00,  1.4509e+00, -2.7294e-01,  6.6798e-01, -6.0282e-01,\n",
       "         1.3553e+00,  1.5464e-01, -3.1031e-01, -1.2205e+00,  1.9776e-01,\n",
       "        -6.1631e-01, -1.4231e+00,  7.0942e-02, -2.1925e+00, -1.1945e+00,\n",
       "        -4.4609e-01, -4.4602e-01, -2.5478e-02, -6.1157e-01, -1.8433e+00,\n",
       "         1.1302e+00, -5.6358e-01, -1.2667e+00, -4.3582e-01,  1.0243e-01,\n",
       "         6.9653e-01,  1.3134e-01,  1.2359e+00,  5.8186e-01, -6.0440e-01,\n",
       "         1.2638e+00,  1.0152e+00, -1.2511e+00, -9.5100e-01, -3.0678e-01,\n",
       "        -6.5818e-01, -4.7359e-01, -1.2416e-01,  1.7954e-01,  1.9649e+00,\n",
       "         4.5618e-01, -9.7257e-01,  2.0564e-01, -1.3784e+00,  1.3488e+00,\n",
       "        -1.3863e+00,  3.7847e-01, -6.8884e-01,  1.0267e-01,  4.4249e-01,\n",
       "        -1.1994e+00,  1.8679e-01,  3.1443e-01, -9.9355e-01,  8.0815e-01,\n",
       "         1.2693e+00, -7.4637e-01,  8.8425e-01,  8.0072e-01, -2.2490e-01,\n",
       "        -1.3967e-01,  5.4698e-01, -3.0806e-02,  6.9212e-01,  4.5027e-01,\n",
       "        -2.0528e+00, -9.7731e-04, -8.0116e-01,  5.2899e-01, -1.4570e+00,\n",
       "        -2.4170e+00,  7.3743e-01, -5.1778e-01, -1.6984e+00,  1.3992e+00,\n",
       "        -5.8827e-01, -3.6160e-01, -2.0738e-01,  1.7546e+00,  3.1943e-01,\n",
       "        -8.7164e-01, -7.1234e-01,  1.4035e+00, -7.6433e-01,  7.1514e-01,\n",
       "         2.3912e-02, -1.0215e+00, -3.2834e-01, -1.3462e+00, -4.4023e-01,\n",
       "        -5.7260e-02,  1.6686e+00], requires_grad=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.randn(1,int(X[1].numel()), requires_grad=True, dtype=torch.float64)\n",
    "#b = torch.randn(1,int(X.numel()/X[1].numel()), dtype=torch.float64)\n",
    "#w = torch.randn(2, 3, requires_grad=True)\n",
    "#b = torch.randn(2, requires_grad=True)\n",
    "b = torch.randn(int(X.numel()/X[1].numel()), requires_grad=True)\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearReg(X):\n",
    "    y_t = X @ w.transpose(0,1)  + b\n",
    "    return y_t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearReg(X)\n",
    "loss = rmse(y,LinearReg(X))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "b.numel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/alissom/Documentos/Projetos_py/mlg/mlg.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alissom/Documentos/Projetos_py/mlg/mlg.ipynb#ch0000012?line=5'>6</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alissom/Documentos/Projetos_py/mlg/mlg.ipynb#ch0000012?line=6'>7</a>\u001b[0m     w \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m learning_rate \u001b[39m*\u001b[39m w\u001b[39m.\u001b[39mgrad\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/alissom/Documentos/Projetos_py/mlg/mlg.ipynb#ch0000012?line=7'>8</a>\u001b[0m     b \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m learning_rate \u001b[39m*\u001b[39;49m b\u001b[39m.\u001b[39;49mgrad\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alissom/Documentos/Projetos_py/mlg/mlg.ipynb#ch0000012?line=8'>9</a>\u001b[0m     w\u001b[39m.\u001b[39mgrad \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alissom/Documentos/Projetos_py/mlg/mlg.ipynb#ch0000012?line=9'>10</a>\u001b[0m     b\u001b[39m.\u001b[39mgrad \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "for i in range(100):    \n",
    "    y_hat = X @ w.transpose(0,1)  + b\n",
    "    loss = rmse(y,y_hat)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "        b -= learning_rate * b.grad\n",
    "        w.grad = None\n",
    "        b.grad = None\n",
    "    if i == 50 or i==90:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/alissom/Documentos/Projetos_py/mlg/mlg.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/alissom/Documentos/Projetos_py/mlg/mlg.ipynb#ch0000013?line=0'>1</a>\u001b[0m train_loader[\u001b[39m1\u001b[39;49m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(df.data,df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2859.6903987680657"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(reg.predict(df.data),df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearReg():\n",
    "   def __init__(self):\n",
    "      self.w = torch.randn(1,int(X[1].numel()), requires_grad=True)\n",
    "      self.b = torch.randn(int(X.numel()/X[1].numel()), 1, requires_grad=True)\n",
    "   def LinearReg(X):\n",
    "      y = X.float() @ self.w.transpose(0,1) + self.b\n",
    "      return self.y\n",
    "\n",
    "   def rmse(self,y,y_hat):\n",
    "      return torch.sqrt(((torch.pow(self.y-self.y_hat,2))/torch.numel(self.y)).sum())\n",
    "\n",
    "   def fit(self,X):\n",
    "      learning_rate = 0.01\n",
    "      for i in range(300):\n",
    "         y_hat = LinearReg(X)\n",
    "         loss = rmse(self.y,y_hat)\n",
    "         loss.backward()\n",
    "         with torch.no_grad():\n",
    "            w -= learning_rate * self.w.grad\n",
    "            b -= learning_rate * self.b.grad\n",
    "            self.w.grad = None\n",
    "            self.b.grad = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([261.,  68., 191., 264., 127.,  63., 189., 257.,  88., 184., 252., 110.,\n",
       "        178., 118., 146.,  83., 173., 248., 253., 111.,  71., 122., 150., 132.,\n",
       "         97.], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43bae068c0cf3e26bb718341bc98e1eff693d43b80578fe208d1a851c04b5de8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
