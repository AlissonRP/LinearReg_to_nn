{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlissonRP/LinearReg_to_nn/blob/master/lr_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq-jcdX8ynCR"
      },
      "source": [
        "# Linear Regression from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwfPhhclynCT"
      },
      "source": [
        "Here we are going to implement one of the most basic statistical models:\n",
        "* Linear Regression\n",
        "\n",
        "We can treat linear regression as a simple case of a neural network (nn) where we have one node and the activation function is the identity\n",
        "<p align=\"center\"><img align=\"center\" src=\"https://joshuagoings.com/assets/linear.png\" height=\"370px\" width=\"690\"/></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-33DLncynCU"
      },
      "source": [
        "## Linear Regression\n",
        "The linear regression model is simply a structure that predicts the mean ($\\mu_i$) of the random variable $Y_i$ using a linear combination of the covariates ($X_i$), that is:\n",
        "\n",
        "$$\n",
        "\\mu_i = \\sum_{i = 0}^{n}w_iX_i\n",
        "$$\n",
        "\n",
        "Where $X_i$ is a vector of the column $i$ of the covariate space and $X_0$ = 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jp317p1ynCV"
      },
      "source": [
        "In practice, we have some observations $(x_i,y_i)$ and we do not know the $w_i$, so some estimation method is necessary. The best known and most used method is the least squares method that minimizes the sum of the squared difference of errors, that is:\n",
        "\n",
        "$$\n",
        "\\text{min}_{w_i}\\sum_i (Y_i - {\\mu}_i)²\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2wrJTdPynCX"
      },
      "source": [
        "But here we are going to take an alternative approach, we are going to use the gradient descent as the $w_i$ estimation method\n",
        "\n",
        "## Gradient descent\n",
        "\n",
        "The gradient descent method is an optimization method in which the posterior value of the quantity of interest is calculated by taking the current value and going against the gradient direction, as in general we want to minimize a certain function $g_{\\theta}$ and the gradient goes in the direction that maximizes $g$.  \n",
        "Defining $L$ as our loss function, we want to find the values ​​of $w_i$ that minimize $L$, so we have:\n",
        "$$\n",
        "w_{i+1} = w_i - \\lambda\\dfrac{dL}{dw_i}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6I08OZ5mynCX"
      },
      "source": [
        "## Deep Learning and PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hdkuii22ynCY"
      },
      "source": [
        "In this section, we will calculate the gradients $\\bigg(\\dfrac{dL}{dw_i}\\bigg)$ using backpropagation and then evaluate the loss, and use the gradient descent to optimize the parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc6SqLT2ynCZ"
      },
      "source": [
        "### Why simulated data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyFvqBydynCZ"
      },
      "source": [
        "Let's simulate the data of our response variable $y$, by the following function:\n",
        "$$\n",
        "y = Xw\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghUdX-4oynCZ"
      },
      "source": [
        "Where the $X$ data comes from Poisson distributions with different parameters. We are going to use simulated data because we know **exactly** the value of the parameters, in other words, we know exactly the structure of the data generating function, so we can evaluate the estimation with total precision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "c6ZI1fmsynCa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3AYXLgZdynCc"
      },
      "outputs": [],
      "source": [
        "np.random.seed(41)\n",
        "\n",
        "X = torch.from_numpy(np.random.exponential(scale=15,size =(15,4)))\n",
        "betas = torch.tensor([[1.,3.,15.,-2.]], dtype=torch.float64)\n",
        "b0 = torch.tensor([[2.]], dtype=torch.float64)\n",
        "y = X @ betas.t() + b0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO2w8WgoynCd"
      },
      "source": [
        "So the value of the parameters is specified by the tensor `betas` and `b0`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Wa2JhixFynCd",
        "outputId": "b5ab2711-7880-4be0-96dd-562c29c91484",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.,  3., 15., -2.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "betas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvExTMeHynCe"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djDMN-WdynCe"
      },
      "source": [
        "Here we establish some hyperparameters of the nn\n",
        "\n",
        "* Loss: rmse := $\\sqrt{\\dfrac{1}{n}\\sum_{i= n}^{n}(y - \\hat{y})²}$\n",
        "* Optimizer: Gradient descent := $w_i = w_{i-1} - \\lambda \\dfrac{d \\text{Loss}}{dw_{i-1}}$\n",
        "* $\\lambda$ = 0.001\n",
        "* Initialization values ​​of the weights come from a standard normal distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "5k8_a4xRynCf"
      },
      "outputs": [],
      "source": [
        "\n",
        "# loss function\n",
        "def rmse(y,y_hat):\n",
        "    return torch.sqrt(((torch.pow(y-y_hat,2))/torch.numel(y)).sum())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "HooLCKGUynCf",
        "outputId": "71510a51-a09d-47ac-8c5e-a03a7c4c8d4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.9697], dtype=torch.float64, requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "w = torch.randn(1,int(X[1].numel()), requires_grad=True, dtype=torch.float64)\n",
        "\n",
        "b =  torch.randn(1, requires_grad=True, dtype=torch.float64)\n",
        "\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "XmUd91dXynCg"
      },
      "outputs": [],
      "source": [
        "def LinearReg(inputs):\n",
        "    y_t = inputs @ w.transpose(0,1)  + b\n",
        "    return y_t\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "MtkPxD1nynCh",
        "outputId": "e850c515-bd16-43bf-da69-51b9f11f668f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(478.8392, dtype=torch.float64, grad_fn=<SqrtBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "\n",
        "loss = rmse(y,LinearReg(X))\n",
        "loss.backward()\n",
        "loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see that the initial value is very wrong, so we need to optimize this value. The first step is to \"clear\" the gradients because PyTorch stores them in the object."
      ],
      "metadata": {
        "id": "scjMEL-lv3vP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "th0wM3isynCh",
        "outputId": "4df223ef-2e83-4353-c4de-159d9c5849ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "\n",
        "w.grad.zero_()\n",
        "b.grad.zero_()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the step of optimization, as we see this is a loop because we predict the value, calculate the loss and optimize the parameters and make everything again."
      ],
      "metadata": {
        "id": "b_bdw-xcwmN_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "aVh-QJYuynCh",
        "outputId": "2ce0680b-8c78-482f-afc3-5f2ac1bcf8bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(415.1686, dtype=torch.float64, grad_fn=<SqrtBackward0>)\n",
            "tensor(0.8954, dtype=torch.float64, grad_fn=<SqrtBackward0>)\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.001\n",
        "for i in range(1000):    \n",
        "    y_hat = LinearReg(X)\n",
        "    loss = rmse(y,y_hat)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "        b -= learning_rate * b.grad\n",
        "        w.grad.zero_()\n",
        "        b.grad.zero_()\n",
        "    if i == 50 or i==900:\n",
        "        print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the parameter values ​​are (except for bias which is in `b`) stored in `w`"
      ],
      "metadata": {
        "id": "pZAwmL3ixNrj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "NoOAmwfBynCi",
        "outputId": "654ab8cd-a8e0-4487-fdcc-d79bdd98a7d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0540,  3.0817, 15.0093, -1.9342]], dtype=torch.float64,\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "XLFfMKOCynCj",
        "outputId": "2dc1627a-2e46-4635-d2de-9b1e839c38db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 261.2693],\n",
              "        [  60.0724],\n",
              "        [ 144.7189],\n",
              "        [ 167.7342],\n",
              "        [ 329.7891],\n",
              "        [ 182.9445],\n",
              "        [ 110.9456],\n",
              "        [  79.9302],\n",
              "        [1742.1217],\n",
              "        [ 450.8701],\n",
              "        [ 145.6723],\n",
              "        [ 352.7420],\n",
              "        [ 117.3411],\n",
              "        [ 133.8173],\n",
              "        [ 663.0963]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3YPcgabyN4I",
        "outputId": "77c37dce-036c-4950-8e1f-a33a5993470d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8848, dtype=torch.float64, grad_fn=<SqrtBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "PGghzkKMynCj"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "reg = LinearRegression().fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "7glebvNJynCk",
        "outputId": "386f3882-9da1-4c6a-ec19-f5c1a7c0130e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.562051929831399e-26"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mean_squared_error(reg.predict(X), y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8ThevQuySAw",
        "outputId": "48ceb693-e1ed-4658-ac7d-57546849d263"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 261.26927572],\n",
              "       [  60.07240414],\n",
              "       [ 144.7188992 ],\n",
              "       [ 167.73416625],\n",
              "       [ 329.7891077 ],\n",
              "       [ 182.94448173],\n",
              "       [ 110.9455657 ],\n",
              "       [  79.93022758],\n",
              "       [1742.12174849],\n",
              "       [ 450.87009971],\n",
              "       [ 145.67226933],\n",
              "       [ 352.74195701],\n",
              "       [ 117.34108074],\n",
              "       [ 133.81727535],\n",
              "       [ 663.09627849]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Disclaimer\n",
        "This was done just to learn the basics of PyTorch, evidently the model in this case tends to be overfitting, but the purpose here is not to make predictions but to build the model in a non-traditional approach."
      ],
      "metadata": {
        "id": "bwXFiJW0vwnM"
      }
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "43bae068c0cf3e26bb718341bc98e1eff693d43b80578fe208d1a851c04b5de8"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Lr_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}